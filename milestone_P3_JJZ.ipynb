{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P2 submission\n",
    "\n",
    "**Team :** Laremontada61\n",
    "\n",
    "📖 Abstract\n",
    "\n",
    "In the wide world of hops, cereals and aperitifs with friends, LaRemontADA is on a quest towards making a beer rating system combining the precision of figures and the richness of prose.\n",
    "\n",
    "Using the BeerReviews dataset that contains a variety of beer ratings from 2 different websites together with sentiment analysis tools, out goal is to enhance the already existing rating system to be able to determine the world's best beer. This determination is based on a detailed analysis of the existing ratings throughout the world and across time.\n",
    "\n",
    "❓ **Research questions**\n",
    "\n",
    "During this work, we will give an answer to those questions:\n",
    "\n",
    "- How to enrich the ranking systems with sentiment analysis ?\n",
    "- Are there any external factors that may influence rating ? (such as politics, economics, time of the year...)\n",
    "- Combining all of this, what is the best brewery in the world ?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The notebook's objective for this milestone is to intimately familiarize ourselves with the data, perform thorough preprocessing, and execute all essential descriptive statistical tasks and showcasing the feasibility of our project goals.\n",
    "\n",
    "General organization of this notebook:\n",
    "- Handle size of the data\n",
    "- EDA\n",
    "- Data preprocessing\n",
    "- Feasibility check of projects' methods\n",
    "- Alternatives considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import regex as re\n",
    "import os\n",
    "import warnings\n",
    "import spacy\n",
    "\n",
    "from textblob import TextBlob\n",
    "from IPython.display import display, HTML, Markdown\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, words\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "\n",
    "warnings.filterwarnings('ignore') # remove the warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Handle size of the data\n",
    "\n",
    "### Load ratings.txt\n",
    "\n",
    "We are processing data extracted from two similar beer rating websites: BeerAdvocate and RateBeer. The primary data structure is outlined in \"ratings.txt,\" which includes user reviews providing information on beer (names, IDs, style, alcohol by volume), breweries, and users (date of review, user details, ratings, and comments on various aspects). Other supporting files include \"beers.csv\" (aggregated ratings for each beer), \"Breweries\" (information on breweries and their locations), and \"Users\" (user details on the number of ratings, reviews, and country of origin).\n",
    "\n",
    "The most crucial file is \"ratings.txt,\" as others are derived from its content. Due to its significant size (4.3 GB for BeerAdvocate and 3.95 GB for RateBeer), loading directly with a standard pipeline is impractical due to laptop memory limitations. To address this, we split the .txt files into N subfiles and load the data iteratively using a function.\n",
    "\n",
    "The function allows control over the fraction of initial data loaded via the parameter **Nb_files**, which determines the number of subfiles to load. It also accommodates inherent differences between the two websites, such as additional review columns for BeerAdvocate.\n",
    "\n",
    "Once loaded into DataFrames, we utilize the sample_data function to randomly sample a fraction of the data, enabling efficient handling of the substantial dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_txt_file(website, Nb_files):\n",
    "    if website == 'BeerAdvocate':\n",
    "        # Specify the directory containing the text files \n",
    "        # Need to be outside of the repo folder and might need to change the path according to one's unique folders configuration\n",
    "        directory = './../../dataset_BeerReviews/BeerAdvocate/ratings_split_BA/'\n",
    "    else:\n",
    "        directory = './../../dataset_BeerReviews/RateBeer/ratings_split_RB/'\n",
    "\n",
    "    # Initialize an empty list to store DataFrames\n",
    "    dfs = []\n",
    "\n",
    "    # Loop through the files in reverse order (ratings-5.txt to ratings-1.txt)\n",
    "    for i in range(Nb_files, 0, -1):\n",
    "        file_name = f'ratings-{i}.txt'\n",
    "        file_path = os.path.join(directory, file_name)\n",
    "\n",
    "        with open(file_path, 'r') as f:\n",
    "            text = f.read()\n",
    "\n",
    "        # Remove double quotes at the beginning of each line\n",
    "        data = re.sub('\"', '', text)\n",
    "        data = re.sub(r'^\"', '', data, flags=re.MULTILINE)\n",
    "\n",
    "        # Split the text into individual beer reviews\n",
    "        beer_reviews = data.split('beer_name')\n",
    "\n",
    "        # Extract the beer information from each review\n",
    "        beer_data = []\n",
    "        for review in beer_reviews:\n",
    "            beer_info = {}\n",
    "            for line in [entry.split(':', 1) for entry in review.split('\\n') if ':' in entry]:# and 'text' not in entry]:\n",
    "                if line:  # Check if the list is not empty\n",
    "                    key, value = line[0].strip(), line[1].strip()\n",
    "                    beer_info[key] = value\n",
    "            beer_data.append(beer_info)\n",
    "\n",
    "        # Convert the beer data into a DataFrame\n",
    "        df = pd.DataFrame(beer_data)\n",
    "\n",
    "        # Append the DataFrame to the list\n",
    "        dfs.append(df)\n",
    "\n",
    "    # Concatenate all DataFrames into a single DataFrame\n",
    "    final_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # Rename the columns depending on the website\n",
    "    if website == 'BeerAdvocate':\n",
    "        final_df.columns = [\n",
    "            'beer_name',\n",
    "            'beer_id',\n",
    "            'brewery_name',\n",
    "            'brewery_id',\n",
    "            'style',\n",
    "            'abv',\n",
    "            'date',\n",
    "            'user_name',\n",
    "            'user_id',\n",
    "            'appearance',\n",
    "            'aroma',\n",
    "            'palate',\n",
    "            'taste',\n",
    "            'overall',\n",
    "            'rating',\n",
    "            'text',\n",
    "            'review'] # additional column compared to RB\n",
    "    else:\n",
    "        final_df.columns = [\n",
    "            'beer_name',\n",
    "            'beer_id',\n",
    "            'brewery_name',\n",
    "            'brewery_id',\n",
    "            'style',\n",
    "            'abv',\n",
    "            'date',\n",
    "            'user_name',\n",
    "            'user_id',\n",
    "            'appearance',\n",
    "            'aroma',\n",
    "            'palate',\n",
    "            'taste',\n",
    "            'overall',\n",
    "            'rating',\n",
    "            'text']\n",
    "    return final_df\n",
    "\n",
    "def sample_data(df, ratio):\n",
    "    # sample the data to make it even smaller\n",
    "    return df.sample(frac = ratio, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 16 elements, new values have 17 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load data : for faster processing, we will only load 1 file out of the whole dataset\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m ratings_BA \u001b[38;5;241m=\u001b[39m \u001b[43mload_txt_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBeerAdvocate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m ratings_RB \u001b[38;5;241m=\u001b[39m load_txt_file(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRateBeer\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[12], line 48\u001b[0m, in \u001b[0;36mload_txt_file\u001b[1;34m(website, Nb_files)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Rename the columns depending on the website\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m website \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBeerAdvocate\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 48\u001b[0m     \u001b[43mfinal_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     49\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbeer_name\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     50\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbeer_id\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     51\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbrewery_name\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     52\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbrewery_id\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstyle\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     54\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabv\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     55\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     56\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_name\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     57\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     58\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mappearance\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     59\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maroma\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     60\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpalate\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     61\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtaste\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moverall\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     63\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     64\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     65\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;66;03m# additional column compared to RB\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     67\u001b[0m     final_df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     68\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbeer_name\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     69\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbeer_id\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     83\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\julie\\anaconda3\\envs\\ada\\lib\\site-packages\\pandas\\core\\generic.py:6218\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   6216\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   6217\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n\u001b[1;32m-> 6218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__setattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m   6220\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mproperties.pyx:69\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\julie\\anaconda3\\envs\\ada\\lib\\site-packages\\pandas\\core\\generic.py:767\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[1;34m(self, axis, labels)\u001b[0m\n\u001b[0;32m    762\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    763\u001b[0m \u001b[38;5;124;03mThis is called from the cython code when we set the `index` attribute\u001b[39;00m\n\u001b[0;32m    764\u001b[0m \u001b[38;5;124;03mdirectly, e.g. `series.index = [1, 2, 3]`.\u001b[39;00m\n\u001b[0;32m    765\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    766\u001b[0m labels \u001b[38;5;241m=\u001b[39m ensure_index(labels)\n\u001b[1;32m--> 767\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[1;32mc:\\Users\\julie\\anaconda3\\envs\\ada\\lib\\site-packages\\pandas\\core\\internals\\managers.py:227\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: AxisInt, new_labels: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;66;03m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[1;32m--> 227\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_set_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis] \u001b[38;5;241m=\u001b[39m new_labels\n",
      "File \u001b[1;32mc:\\Users\\julie\\anaconda3\\envs\\ada\\lib\\site-packages\\pandas\\core\\internals\\base.py:85\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m new_len \u001b[38;5;241m!=\u001b[39m old_len:\n\u001b[1;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     86\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength mismatch: Expected axis has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements, new \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     87\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     88\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length mismatch: Expected axis has 16 elements, new values have 17 elements"
     ]
    }
   ],
   "source": [
    "# Load data : for faster processing, we will only load 1 file out of the whole dataset\n",
    "ratings_BA = load_txt_file('BeerAdvocate', 1)\n",
    "ratings_RB = load_txt_file('RateBeer', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data to make it even smaller AND RANDOMIZED (not randomized in the initial txt splitting process)\n",
    "ratings_BA = sample_data(df = ratings_BA, ratio = 0.5)\n",
    "ratings_RB = sample_data(df = ratings_RB, ratio = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Length of ratings_BA (BeerAdvocate) dataframe : {len(ratings_BA)}\")\n",
    "print(f\"Length of ratings_RB (RateBeer) dataframe : {len(ratings_RB)}\")\n",
    "display(ratings_BA.head(2),ratings_RB.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the other data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BeerAdvocate\n",
    "beers_BA = pd.read_csv(\"./dataset_BeerReviews/BeerAdvocate/beers.csv\")\n",
    "breweries_BA = pd.read_csv(\"./dataset_BeerReviews/BeerAdvocate/breweries.csv\")\n",
    "users_BA = pd.read_csv(\"./dataset_BeerReviews/BeerAdvocate/users.csv\")\n",
    "\n",
    "# RateBeer\n",
    "beers_RB = pd.read_csv(\"./dataset_BeerReviews/RateBeer/beers.csv\")\n",
    "breweries_RB = pd.read_csv(\"./dataset_BeerReviews/RateBeer/breweries.csv\")\n",
    "users_RB = pd.read_csv(\"./dataset_BeerReviews/RateBeer/users.csv\")\n",
    "\n",
    "# matched_beer_data\n",
    "beers_matched = pd.read_csv(\"./dataset_BeerReviews/matched_beer_data/beers.csv\", header=1)\n",
    "breweries_matched = pd.read_csv(\"./dataset_BeerReviews/matched_beer_data/breweries.csv\", header = 1)\n",
    "ratings_matched = pd.read_csv(\"./dataset_BeerReviews/matched_beer_data/ratings.csv\", header=1)\n",
    "users_approx = pd.read_csv(\"./dataset_BeerReviews/matched_beer_data/users_approx.csv\", header=1)\n",
    "users_matched = pd.read_csv(\"./dataset_BeerReviews/matched_beer_data/users.csv\", header=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## EDA\n",
    "\n",
    "**Organisation of the EDA**\n",
    "- General\n",
    "- Numerical ratings\n",
    "- Textual reviews\n",
    "\n",
    "### 1. General\n",
    "\n",
    "**Formats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get types of features in each DataFrame\n",
    "df_types = pd.concat([df.dtypes.rename(f\"DataFrame {i+1}\") for i, df in enumerate([ratings_BA, ratings_RB])], axis=1)\n",
    "df_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can see that all the features of **ratings_BA** and **ratings_RB** have a `object` type, which is not very convenient if we want to automate the visualization process, for example plotting the distribution of the numerical features in histograms. As a first preprocessing step, we will thus convert the type of the numerical variables to `float64` with the function **convert_type** below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_type(df, col):\n",
    "    #try:\n",
    "    df[col] = df[col].astype('float64')\n",
    "    #except ValueError:\n",
    "    #    pass\n",
    "    return df\n",
    "\n",
    "# columns including the numerical features for both websites\n",
    "# user_id is numerical in RB but categorical in BA so we don't include it\n",
    "numerical_cols = ['beer_id', 'brewery_id', 'abv', 'appearance', 'aroma', 'palate', 'taste', 'overall', 'rating']\n",
    "\n",
    "for col in numerical_cols : \n",
    "    ratings_BA = convert_type(ratings_BA, col)\n",
    "    ratings_RB = convert_type(ratings_RB, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get types of features in each DataFrame\n",
    "df_types = pd.concat([df.dtypes.rename(f\"DataFrame {i+1}\") for i, df in enumerate([ratings_BA, ratings_RB])], axis=1)\n",
    "df_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descriptive statistics**\n",
    "\n",
    "We can see the missing values per feature in each dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_stats(df):\n",
    "        \"\"\"\n",
    "        Obtains descriptive statistics for all features and percentage of missing values\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : DataFrame containing all data\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        stats : DataFrame containing the statistics for all features.\n",
    "        \"\"\"\n",
    "        # Calculate numerical descriptive statistics \n",
    "        numerical = df.describe(include= ['float64', 'int64'])\n",
    "        # Calculate categorical descriptive statistics\n",
    "        categorical = df.describe(include= ['object'])\n",
    "        # Combine numerical and categorical statistics into a single DataFrame\n",
    "        stats = pd.concat([numerical, categorical])\n",
    "        \n",
    "        # Select specific statistics for the output\n",
    "        stats = stats.loc[['mean', 'std', '50%', 'unique', 'freq', 'max']]\n",
    "        # Calculate the percentage of missing values for each feature\n",
    "        percentage = df.isnull().sum(axis = 0)*100 / len(df)\n",
    "        # Add a row to the DataFrame containing the percentage of missing values for each feature\n",
    "        stats.loc['missing_values'] = np.array(percentage)\n",
    "        return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(get_feature_stats(ratings_BA), get_feature_stats(ratings_RB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = get_feature_stats(breweries_BA)\n",
    "df2 = get_feature_stats(breweries_RB)\n",
    "df3 = get_feature_stats(users_BA)\n",
    "df4 = get_feature_stats(users_RB)\n",
    "\n",
    "# Using HTML/CSS to display DataFrames in the same row\n",
    "html = f'<div style=\"display: flex; flex-direction: row;\"> \\\n",
    "            <div style=\"text-align: center; margin-right: 20px;\"> \\\n",
    "                <h3>Breweries BeerAdvocate</h3>{df1.to_html()} \\\n",
    "            </div> \\\n",
    "            <div style=\"text-align: center; margin-right: 100px;\"> \\\n",
    "                <h3>Breweries RateBeer</h3>{df2.to_html()} \\\n",
    "            </div> \\\n",
    "            <div style=\"text-align: center; margin-right: 20px;\"> \\\n",
    "                <h3>Users BeerAdovate</h3>{df3.to_html()} \\\n",
    "            </div> \\\n",
    "            <div style=\"text-align: center;\"> \\\n",
    "                <h3>Users RateBeer</h3>{df4.to_html()} \\\n",
    "            </div> \\\n",
    "        </div>'\n",
    "\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Graphical descriptions**\n",
    "\n",
    "- **Users**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(users_BA.head(2), users_RB.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nNumber of unique users (based on user_name) in BeerAdvocate: {len(users_BA['user_name'].unique())}\")\n",
    "print(f\"Number of unique users (based on user_name) in RateBeer: {len(users_RB['user_name'].unique())}\")\n",
    "\n",
    "print(f\"\\nNumber of unique location for the users in BeerAdvocate: {len(users_BA['location'].unique())}\")\n",
    "print(f\"Number of unique location for the users in RateBeer: {len(users_RB['location'].unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Breweries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(breweries_BA.head(2), breweries_RB.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nNumber of unique breweries (based on name) in BeerAdvocate: {len(breweries_BA['name'].unique())}\")\n",
    "print(f\"Number of unique breweries (based on name) in RateBeer: {len(breweries_RB['name'].unique())}\")\n",
    "\n",
    "print(f\"\\nNumber of unique location for the breweries in BeerAdvocate: {len(breweries_BA['location'].unique())}\")\n",
    "print(f\"Number of unique location for the breweries in RateBeer: {len(breweries_RB['location'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of beers for each location\n",
    "def count_Top_10(breweries_df):\n",
    "    # Count the number of beers per location\n",
    "    number_of_beer_per_country = breweries_df['location'].value_counts()\n",
    "    # Identify the top 10 breweries by location\n",
    "    top_10_breweries_location = number_of_beer_per_country.nlargest(10)\n",
    "    return top_10_breweries_location, number_of_beer_per_country\n",
    "\n",
    "top_10_breweries_location_RB, _ = count_Top_10(breweries_RB)\n",
    "top_10_breweries_location_BA, _ = count_Top_10(breweries_BA)\n",
    "\n",
    "_ , number_of_beer_per_country_RB = count_Top_10(breweries_RB)\n",
    "_ , number_of_beer_per_country_BA = count_Top_10(breweries_BA)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "sns.barplot(x=top_10_breweries_location_BA.index, y=top_10_breweries_location_BA.values, alpha=0.8, palette=sns.color_palette(\"colorblind\"), ax=axs[0])\n",
    "axs[0].set_title('Distribution of Locations for BeerAdvocate')\n",
    "axs[0].set_ylabel('Number of beers')\n",
    "axs[0].set_xlabel('Location')\n",
    "axs[0].tick_params(axis='x', rotation=90)\n",
    "\n",
    "sns.barplot(x=top_10_breweries_location_RB.index, y=top_10_breweries_location_RB.values, alpha=0.8, palette=sns.color_palette(\"colorblind\"), ax=axs[1])\n",
    "axs[1].set_title('Distribution of Locations for RateBeer')\n",
    "axs[1].set_ylabel('Number of beers')\n",
    "axs[1].set_xlabel('Location')\n",
    "axs[1].tick_params(axis='x', rotation=90)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this plot, one could say that the top 10 location with the greater number of beers seems well spread. But when taking a closer look at the data it is noticeable that in the United States there is a location per state, meaning that the total number of beers in the US is not well represented here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtering_us(breweries_df, number_of_beer_per_country):\n",
    "    # Create a category that gathers all the US beers in one location\n",
    "    # Count number of beers in the US\n",
    "    nb_us_beers = breweries_df[breweries_df['location'].str.startswith('United States,')].value_counts().sum()\n",
    "\n",
    "    # Modify world wide beer count to gather all the US beers in one category \n",
    "    us_filtered = number_of_beer_per_country[~number_of_beer_per_country.index.str.startswith('United States,')]\n",
    "    us_filtered.loc['United States'] = nb_us_beers\n",
    "\n",
    "    us_filtered = us_filtered.nlargest(10)\n",
    "    return us_filtered\n",
    "\n",
    "us_filtered_RB = filtering_us(breweries_RB, number_of_beer_per_country_RB)\n",
    "us_filtered_BA = filtering_us(breweries_BA, number_of_beer_per_country_BA)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "sns.barplot(x=us_filtered_BA.index, y=us_filtered_BA.values, alpha=0.8, palette=sns.color_palette(\"colorblind\"), ax=axs[0])\n",
    "axs[0].set_title('Distribution of Locations for BeerAdvocate')\n",
    "axs[0].set_ylabel('Number of beers')\n",
    "axs[0].set_xlabel('Location')\n",
    "axs[0].tick_params(axis='x', rotation=90)\n",
    "\n",
    "sns.barplot(x=us_filtered_RB.index, y=us_filtered_RB.values, alpha=0.8, palette=sns.color_palette(\"colorblind\"), ax=axs[1])\n",
    "axs[1].set_title('Distribution of Locations for RateBeer')\n",
    "axs[1].set_ylabel('Number of beers')\n",
    "axs[1].set_xlabel('Location')\n",
    "axs[1].tick_params(axis='x', rotation=90)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is more evident that for both datasets (RateBeer and BeerAdvocate) there is a significantly larger number of beers coming from the US, which means that the distribution of the data could be more relevant in this location. This can be interesting if another deeper analysis is done specifically for the US."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Ratings** dataframes\n",
    "\n",
    "As seen above, there are more than  16 000 unique breweries for BeerAdvocate and more than 24 000 for RateBeer. We thus cannot visualize all of them at once. We thus used the function **filter_topk_breweries** to only visualize the breweries that appear the most tn the dataframes ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of different breweries in BA : {len(ratings_BA['brewery_id'].unique())}\")\n",
    "print(f\"Number of different breweries in RB : {len(ratings_RB['brewery_id'].unique())}\")\n",
    "\n",
    "def filter_topk_breweries(df, k):\n",
    "    # Find the top k% of breweries most rated\n",
    "    brewery_count = pd.DataFrame({\"count\": df.groupby('brewery_name').apply(lambda x: len(x))})\n",
    "    threshold = brewery_count['count'].quantile(k)\n",
    "    top_breweries = brewery_count[brewery_count['count'] > threshold].index\n",
    "\n",
    "    # Filter DataFrame based on the selected brewery names\n",
    "    df_filtered = df[df['brewery_name'].isin(top_breweries)]\n",
    "    return df_filtered\n",
    "\n",
    "ratings_BA_top5_breweries = filter_topk_breweries(ratings_BA, 0.95)\n",
    "ratings_RB_top5_breweries = filter_topk_breweries(ratings_RB, 0.95)\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(15, 15))\n",
    "sns.countplot(y='brewery_name', data = ratings_BA_top5_breweries, order = ratings_BA_top5_breweries['brewery_name'].value_counts().index, ax = axs[0])\n",
    "sns.countplot(y='brewery_name', data = ratings_RB_top5_breweries, order = ratings_RB_top5_breweries['brewery_name'].value_counts().index, ax = axs[1])\n",
    "\n",
    "axs[0].set_title(\"Distribution top 5% breweries in BeerAdvocate\")\n",
    "axs[1].set_title(\"Distribution top 5% breweries in RateBeer\")\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set_xlabel(\"Number of ratings\")\n",
    "    ax.set_ylabel(\"Brewery\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Style**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of different style of beers in BA : {len(ratings_BA['style'].unique())}\")\n",
    "print(f\"Number of different style of beers in RB : {len(ratings_RB['style'].unique())}\")\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(15, 12), sharex = True)\n",
    "sns.countplot(y='style', data=ratings_BA, order = ratings_BA['style'].value_counts().index,ax = axs[0])\n",
    "sns.countplot(y='style', data=ratings_RB, order = ratings_RB['style'].value_counts().index,ax = axs[1])\n",
    "\n",
    "axs[0].set_title(\"Distribution beers' style in BeerAdvocate\")\n",
    "axs[1].set_title(\"Distribution beers' style in RateBeer\")\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set_xlabel(\"Number of ratings\")\n",
    "    ax.set_ylabel(\"Style\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, we define a function `filter_topk_styles` that will allow us to plot only the styles most represented in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_topk_styles(df, k):\n",
    "    # Find the top k% of breweries most rated\n",
    "    style_count = pd.DataFrame({\"count\": df.groupby('style').apply(lambda x: len(x))})\n",
    "    threshold = style_count['count'].quantile(k)\n",
    "    top_styles = style_count[style_count['count'] > threshold].index\n",
    "\n",
    "    # Filter DataFrame based on the selected brewery names\n",
    "    df_filtered = df[df['style'].isin(top_styles)]\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Numerical features\n",
    "\n",
    "- abv\n",
    "- appearance\n",
    "- aroma\n",
    "- palate\n",
    "- taste\n",
    "- overall\n",
    "- rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_features(df, title):\n",
    "    continuous_cols = ['abv', 'appearance', 'aroma', 'palate', 'taste', 'overall', 'rating'] \n",
    "    fig, axes = plt.subplots(2, 4, figsize=(15,10))\n",
    "    for i, col in enumerate(continuous_cols):\n",
    "        ax = axes[i // 4, i % 4]\n",
    "        data = df[~df[col].isna()]\n",
    "        sns.histplot(data=data[col], bins=50, ax=ax) \n",
    "    fig.suptitle(title)\n",
    "    fig.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_features(df1, df2, title):\n",
    "    continuous_cols = ['abv', 'appearance', 'aroma', 'palate', 'taste', 'overall', 'rating']\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(20,10))\n",
    "    fig.delaxes(axes[1, 3])\n",
    "    for i, col in enumerate(continuous_cols):\n",
    "        ax = axes[i // 4, i % 4]\n",
    "        sns.histplot(data=df1[~df1[col].isna()], x=col, bins=50, ax=ax, color='skyblue', alpha=0.5, label='BeerAdvocate')\n",
    "        sns.histplot(data=df2[~df2[col].isna()], x=col, bins=50, ax=ax, color='salmon', alpha=0.5, label='RateBeer')\n",
    "        ax.set_title(col)\n",
    "        ax.legend()\n",
    "    fig.suptitle(title)\n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "\n",
    "fig = plot_features(ratings_BA, ratings_RB, \"Distribution of numerical features without missing values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This mosaique plots highlights the differences in the notation between the two websites. Especially in teh appearance and palate categories: RateBeer users are not allowed to put non integer values. This is not the case for BeerAdvocate users. This is why the distribution of the RateBeer ratings is more discrete than the BeerAdvocate one.\n",
    "One another side, the overall ratings in RateBeer and BeerAdvocate are not on the same scales: 5-scale for BeerAdvocate and 20-scale for RateBeer.\n",
    "\n",
    "Later on in this notebooks, the values will be normalized for better comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Scores - styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "# Best rated styles for BeerAdvocate\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.barplot(x=ratings_BA.groupby('style')['overall'].mean().sort_values(ascending=False).head(20).index,\n",
    "            y=ratings_BA.groupby('style')['overall'].mean().sort_values(ascending=False).head(20).values, palette=sns.color_palette(\"colorblind\"))\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Top 20 styles by score (BeerAdvocate)')\n",
    "\n",
    "# Best rated styles for RateBeer \n",
    "plt.subplot(1, 2, 2)\n",
    "sns.barplot(x=ratings_RB.groupby('style')['overall'].mean().sort_values(ascending=False).head(20).index,\n",
    "            y=ratings_RB.groupby('style')['overall'].mean().sort_values(ascending=False).head(20).values, palette=sns.color_palette(\"colorblind\"))\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Top 20 styles by score (RateBeer)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the beer styles with the best average score gives a good idea of the top styles and will be useful for the final visualisation of the best breweries in the world with the best styles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average score for each style and take the top 20 for RateBeer\n",
    "\n",
    "def style_order_fcn(beers_df):\n",
    "    style_order = beers_df.groupby('style')['overall'].mean().sort_values(ascending=False).head(20).index\n",
    "    return style_order\n",
    "\n",
    "style_order_BA = style_order_fcn(ratings_BA)\n",
    "style_order_RB = style_order_fcn(ratings_RB)\n",
    "\n",
    "# Create the boxplots\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "# Create the boxplot for BeerAdvocate\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(x='style', y='overall', data=ratings_BA[ratings_BA['style'].isin(style_order_BA)], order=style_order_BA, palette=sns.color_palette(\"colorblind\"))\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Distribution of score by style for top 20 styles (BeerAdvocate)')\n",
    "\n",
    "# Create the boxplot for RateBeer\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(x='style', y='overall', data=ratings_RB[ratings_RB['style'].isin(style_order_RB)], order=style_order_RB, palette=sns.color_palette(\"colorblind\"))\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Distribution of average score by style for top 20 styles (RateBeer)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To go deeper in the analysis of the top styles these boxplots show the repartition of the scores. These informations are useful to get a real idea of the overall score distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Scores - breweries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_breweries_fcn(beers_df):\n",
    "    #Identify breweries with most 5 rated beers for RateBeer\n",
    "    beer_score_5 = beers_df[beers_df['avg_computed'] == 5]\n",
    "    # Count the occurrences of each brewery\n",
    "    brewery_counts = beer_score_5['brewery_name'].value_counts().nlargest(10)\n",
    "\n",
    "    # Create a DataFrame with the top 10 breweries and their counts\n",
    "    top_breweries = pd.DataFrame({'brewery_name': brewery_counts.index, 'count': brewery_counts.values})\n",
    "    return top_breweries, beer_score_5\n",
    "\n",
    "top_breweries_BA, _ = top_breweries_fcn(beers_BA)\n",
    "top_breweries_RB, _ = top_breweries_fcn(beers_RB)\n",
    "\n",
    "_ , beer_score_5_BA = top_breweries_fcn(beers_BA)\n",
    "_ , beer_score_5_RB = top_breweries_fcn(beers_RB)\n",
    "\n",
    "# Create the barplots\n",
    "plt.figure(figsize=(12, 3))\n",
    "\n",
    "# Create a barplot for BeerAdvocate\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.barplot(x='brewery_name', y='count', data=top_breweries_BA, palette=sns.color_palette(\"colorblind\"))\n",
    "plt.title('Number of 5-rated Beers per Brewery (Top 10 BeerAdvocate)')\n",
    "plt.xlabel('Brewery Name')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Create a barplot for RateBeer\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.barplot(x='brewery_name', y='count', data=top_breweries_RB, palette=sns.color_palette(\"colorblind\"))\n",
    "plt.title('Number of 5-rated Beers per Brewery (Top 10 RateBeer)')\n",
    "plt.xlabel('Brewery Name')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the \"breweries\" and \"beers\" dataframes were used instead of rating because the number of five rated beers is normalized by the number of beers per brewery in the next section.\n",
    "The selection of the breweries with the best number of five rated beers goes along with the idea of finding the best breweries in the world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_10_proportion(breweries_df, beer_score_5):\n",
    "    # Create dataframe for breweries with 5 rated beers\n",
    "    breweries_5 = breweries_df[breweries_df['id'].isin(beer_score_5['brewery_id'])]\n",
    "    breweries_5.rename(columns={'name': 'brewery_name'}, inplace=True)\n",
    "\n",
    "    # Isolate brewery infos \n",
    "    brewery_counts_all = beer_score_5['brewery_name'].value_counts()\n",
    "    brewery_count_df = pd.DataFrame({'brewery_name': brewery_counts_all.index, 'count': brewery_counts_all.values})\n",
    "\n",
    "    # Determining the proportion of 5 rated beers\n",
    "    # Merge DataFrames on the 'brewery_name' column\n",
    "    proportion_of_5_df = pd.merge(breweries_5, brewery_count_df, on='brewery_name', how='inner')\n",
    "\n",
    "    # Exclude breweries with less than 2 beers to get meaningful proportions\n",
    "    proportion_of_5_df = proportion_of_5_df[proportion_of_5_df['nbr_beers'] >= 2]\n",
    "\n",
    "    # Perform division\n",
    "    proportion_of_5_df['proportion'] = proportion_of_5_df['count'] / proportion_of_5_df['nbr_beers']\n",
    "\n",
    "    # Taking Top 10 breweries\n",
    "    Top_10_breweries = proportion_of_5_df.sort_values('proportion', ascending=False).head(10)\n",
    "    \n",
    "    return Top_10_breweries\n",
    "\n",
    "Top_10_breweries_BA = top_10_proportion(breweries_BA, beer_score_5_BA)\n",
    "Top_10_breweries_RB = top_10_proportion(breweries_RB, beer_score_5_RB)\n",
    "\n",
    "# Create a histogram of the top 10 breweries with the most 5 rated beers ordered by proportion\n",
    "plt.figure(figsize=(12, 3))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.barplot(x='brewery_name', y='proportion', data=Top_10_breweries_BA, palette=sns.color_palette(\"colorblind\"))\n",
    "plt.title('Proportion of 5-rated Beers per Brewery (Top 10 BeerAdvocate)')\n",
    "plt.xlabel('Brewery Name')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Proportion')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.barplot(x='brewery_name', y='proportion', data=Top_10_breweries_RB, palette=sns.color_palette(\"colorblind\"))\n",
    "plt.title('Proportion of 5-rated Beers per Brewery (Top 10 for RateBeer)')\n",
    "plt.xlabel('Brewery Name')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Proportion')\n",
    "\n",
    "plt.subplots_adjust(wspace=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot, shows the proportion of 5 rated beers for the best breweries. Breweries with only one beer were filtered to get more relevant proportions.\n",
    "On this plot it seems that the data from BeerAdvocate is more representative given that the proportions displayed are not just equal to one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_correlations(df1, df2):\n",
    "        \"\"\"\n",
    "        Calculates the correlation between all numerical features.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        df1 : DataFrame\n",
    "                First dataframe containing all data\n",
    "        df2 : DataFrame\n",
    "                Second dataframe containing all data\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        # Extract numerical columns from the first dataframe and calculate correlation\n",
    "        numerical_cols1 = df1.select_dtypes(include=['float64', 'int64']).columns\n",
    "        corr1 = df1[numerical_cols1].corr()\n",
    "\n",
    "        # Extract numerical columns from the second dataframe and calculate correlation\n",
    "        numerical_cols2 = df2.select_dtypes(include=['float64', 'int64']).columns\n",
    "        corr2 = df2[numerical_cols2].corr()\n",
    "\n",
    "        # Create subplots for heatmaps of correlations between numerical features in both dataframes\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        sns.heatmap(corr1, annot=True, ax=axes[0])\n",
    "        sns.heatmap(corr2, annot=True, ax=axes[1])\n",
    "        \n",
    "        # Set titles for the subplots\n",
    "        axes[0].set_title('Correlation between numerical features in BeerAdvocate')\n",
    "        axes[1].set_title('Correlation between numerical features in RateBeer')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_correlations(ratings_BA, ratings_RB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing correlation help having a better understanding of the beer rating. One can note that the most relevant part is the lower right corner of the correlation matrix, as the correlation between beer_id and brewery_id might not tell us much. The lower right areas of the matrices look warmer, translating a high correlation between features. Looking at the rating, from the matrices one can see that a beer rater tends to put high rate scores to tastier, and more complex beers.\n",
    "\n",
    "One difference between the 2 websites is that the correlations are different especially in the appearance where BeerAdvocate's users look like they are more focused towards it when rating the beverage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Textual reviews\n",
    "\n",
    "**Number of words in textual reviews**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_words_BA = np.mean(ratings_BA[\"text\"].apply(lambda row : len(str(row))))\n",
    "mean_words_RB = np.mean(ratings_RB[\"text\"].apply(lambda row : len(str(row))))\n",
    "print(f\"Average number of words in textual reviews of BeerAdvocate : {mean_words_BA}\")\n",
    "print(f\"Average number of words in textual reviews of RareBeer : {mean_words_RB}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**N most common words in textual reviews**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_i_gram(corpus, i, n=None):\n",
    "    \"\"\"\n",
    "    Extracts the top 'n' n-grams from a corpus.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    corpus : Series or list\n",
    "        Contains text data.\n",
    "    i : int\n",
    "        Specifies the 'i' in n-grams.\n",
    "    n : int, optional\n",
    "        Specifies the number of top n-grams to return. Default is None.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    words_freq : list\n",
    "        Contains tuples of n-grams and their frequencies.\n",
    "    \"\"\"\n",
    "    # Drop rows with NaN values in the 'text' column\n",
    "    corpus = corpus.dropna()\n",
    "    # Fit CountVectorizer with specified n-gram range\n",
    "    vec = CountVectorizer(ngram_range=(i,i)).fit(corpus)\n",
    "    # Transform the corpus into a bag of words\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    # Sum the occurrences of each word across the corpus\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    # Create a list of tuples containing words and their frequencies\n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    # Sort the list by frequency in descending order\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can take 5-7 min to run\n",
    "N = 20\n",
    "\n",
    "# BeerAdvocate\n",
    "common_unigrams_BA = get_top_n_i_gram(ratings_BA['text'], 1, N)\n",
    "common_bigrams_BA = get_top_n_i_gram(ratings_BA['text'], 2, N)\n",
    "common_trigrams_BA = get_top_n_i_gram(ratings_BA['text'], 3, N)\n",
    "# Rate Beer\n",
    "common_unigrams_RB = get_top_n_i_gram(ratings_RB['text'], 1, N)\n",
    "common_bigrams_RB = get_top_n_i_gram(ratings_RB['text'], 2, N)\n",
    "common_trigrams_RB = get_top_n_i_gram(ratings_RB['text'], 3, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ngrams(common_unigrams, common_bigrams, common_trigrams):\n",
    "    # Creating subplots\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(17, 5))\n",
    "\n",
    "    # Subplot 1: Common Unigrams\n",
    "    df1 = pd.DataFrame(common_unigrams, columns=['Review Text', 'count'])\n",
    "    df1.groupby('Review Text').sum()['count'].sort_values(ascending=False).plot(kind='barh', y='Count', ax=axes[0])\n",
    "    axes[0].set_title(f'Top {N} words in reviews')\n",
    "\n",
    "    # Subplot 2: Common Bigrams\n",
    "    df2 = pd.DataFrame(common_bigrams, columns=['Review Text', 'count'])\n",
    "    df2.groupby('Review Text').sum()['count'].sort_values(ascending=False).plot(kind='barh', y='Count', ax=axes[1])\n",
    "    axes[1].set_title(f'Top {N} bigrams in reviews')\n",
    "\n",
    "    # Subplot 3: Common Trigrams\n",
    "    df3 = pd.DataFrame(common_trigrams, columns=['Review Text', 'count'])\n",
    "    df3.groupby('Review Text').sum()['count'].sort_values(ascending=False).plot(kind='barh', y='Count', ax=axes[2])\n",
    "    axes[2].set_title(f'Top {N} trigrams in reviews')\n",
    "\n",
    "    # Adjust layout and display\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"##### BeerAdvocate\"))\n",
    "plot_ngrams(common_unigrams_BA, common_bigrams_BA, common_trigrams_BA)\n",
    "display(Markdown(\"##### RateBeer\"))\n",
    "plot_ngrams(common_unigrams_RB, common_bigrams_RB, common_trigrams_RB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these plots, we observe that there are a lot of words not interesting to describe a beer but just useful to write a sentence (eg: and, with,the...). This is what we call stopwords. To have a relevant analysis in the next part we will process the sentences.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation\n",
    "\n",
    "- Standardization of numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_numerical_data(df):\n",
    "    \"\"\"\n",
    "    Normalizes the numerical features of the DataFrame.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        Containing all data\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : DataFrame\n",
    "        Containing all data with normalized numerical features.\n",
    "                \n",
    "    \"\"\"\n",
    "    df2 = df.copy()\n",
    "    numerical = df2._get_numeric_data().columns\n",
    "    for col in numerical:\n",
    "        df2[col] = (df2[col] - df2[col].mean()) / df2[col].std()\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_features(normalize_numerical_data(ratings_BA), normalize_numerical_data(ratings_RB), \"Distribution of numerical features without missing values - Normalized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After standardization, the distributions of the different features are made comparable across the 2 websites.\n",
    "\n",
    "The overall scores from the 2 websites follow a very similar distribution although in the beginning they were not on the same scale. This shows that we have enough colledted data.\n",
    "\n",
    "- **date** feature\n",
    "\n",
    "The date feature is hereafter reformated to be processed more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rating_month_feature(df):\n",
    "    \"\"\"\n",
    "    Adds a 'month' feature to the DataFrame based on the 'date' column.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        Contains data including a 'date' column.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_m : DataFrame\n",
    "        Contains the original data with an additional 'month' feature.\n",
    "    \"\"\"\n",
    "    # Create a copy of the DataFrame\n",
    "    df_m = df.copy()\n",
    "    # Conversion of date feature from timestamp to text date\n",
    "    pd.to_numeric(df_m['date'], errors='coerce', downcast='integer')\n",
    "    # Convert 'date' to datetime and extract the date\n",
    "    df_m.date = ratings_BA.date.apply(lambda d: pd.to_datetime(d, unit='s'))\n",
    "    df_m['date'] = df_m['date'].dt.date\n",
    "    df_m.head(2)\n",
    "\n",
    "    # Extract the month from the 'date' column and add it as a new feature 'month'\n",
    "    df_m['month'] = pd.to_datetime(df_m['date']).dt.month\n",
    "\n",
    "    return df_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_BA_monthly = add_rating_month_feature(ratings_BA)\n",
    "ratings_RB_monthly = add_rating_month_feature(ratings_RB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **text** feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('words')\n",
    "nltk.download('stopwords') # Download NLTK stopwords\n",
    "nltk.download('wordnet')   # Lemmatization\n",
    "nltk.download('words')\n",
    "english_words=set(words.words())\n",
    "# Get the set of English stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned previously to have a relevant analysis, we need to transform review texts. To facilitate the comparison we have first remove punctuation, capital letters and remove the stopwords we have talked about. Another function lemmatize the senctences that means \"grouping together the inflected forms of a word so they can be analysed as a single item\" (Wikipedia definition). For example drinking will be rewrite drink.\n",
    "We have also removed not english-words to facilitate the analysis and the polarity sentiment. Indeed, in the EDA part we could see that there are different languages in the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from translate import Translator\n",
    "\n",
    "\n",
    "def preprocess_sentences(df):    \n",
    "    # Remove rows with no sentences (NaN values or empty sentences)\n",
    "    df = df.dropna(subset=['text'])\n",
    "    df = df[df['text'].str.strip().astype(bool)]\n",
    "    # Rest of the code remains the same\n",
    "    def clean_text(sentence):\n",
    "        translator = str.maketrans('', '', string.punctuation)\n",
    "        cleaned = sentence.translate(translator).lower()\n",
    "        return cleaned\n",
    "\n",
    "    def lemmatize_text(sentence):\n",
    "        tokens = word_tokenize(sentence)\n",
    "        lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "        return ' '.join(lemmatized_tokens)\n",
    "\n",
    "    def remove_stopwords(sentence):\n",
    "        tokens = word_tokenize(sentence)\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stop_words]\n",
    "        return ' '.join(filtered_tokens)\n",
    "\n",
    "    def keep_only_english(sentence):\n",
    "        return \" \".join(w for w in nltk.wordpunct_tokenize(sentence) if w.lower() in english_words or not w.isalpha())\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    df['cleaned_text'] = df['text'].apply(clean_text)\n",
    "    df['cleaned_text'] = df['cleaned_text'].apply(lemmatize_text)\n",
    "    df['cleaned_text'] = df['cleaned_text'].apply(remove_stopwords)\n",
    "    df['cleaned_text'] = df['cleaned_text'].apply(keep_only_english)\n",
    "    return df\n",
    "\n",
    "def compute_top_words(df):\n",
    "    # Split the sentences into individual words\n",
    "    all_words = ' '.join(df['cleaned_text']).split()\n",
    "\n",
    "    # Count word occurrences\n",
    "    word_counts = Counter(all_words)\n",
    "\n",
    "    # Get the top 20 most common words\n",
    "    top_words = word_counts.most_common(20)\n",
    "\n",
    "    # Convert to DataFrame for easy plotting\n",
    "    top_words_df = pd.DataFrame(top_words, columns=['Word', 'Count'])\n",
    "    \n",
    "    return top_words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can take 6-8 min to run on all the sentences\n",
    "ratings_BA_cleaned = preprocess_sentences(ratings_BA)\n",
    "ratings_RB_cleaned = preprocess_sentences(ratings_RB)\n",
    "\n",
    "# correction to remove missing sentences\n",
    "ratings_BA_cleaned = ratings_BA_cleaned[ratings_BA_cleaned['cleaned_text'] != 'nan']\n",
    "ratings_RB_cleaned = ratings_RB_cleaned[ratings_RB_cleaned['cleaned_text'] != 'nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before preprocessing of the sentences\n",
    "print(\"Before cleaning\")\n",
    "mean_words_BA = np.mean(ratings_BA[\"text\"].apply(lambda row : len(str(row))))\n",
    "mean_words_RB = np.mean(ratings_RB[\"text\"].apply(lambda row : len(str(row))))\n",
    "print(f\"Average number of words in textual reviews of BA : {mean_words_BA}\")\n",
    "print(f\"Average number of words in textual reviews of RB : {mean_words_RB}\")\n",
    "\n",
    "# After preprocessing of the sentences\n",
    "print(\"\\nAfter cleaning\")\n",
    "mean_words_BA = np.mean(ratings_BA_cleaned[\"cleaned_text\"].apply(lambda row : len(str(row))))\n",
    "mean_words_RB = np.mean(ratings_RB_cleaned[\"cleaned_text\"].apply(lambda row : len(str(row))))\n",
    "print(f\"Average number of words in textual reviews of BA : {mean_words_BA}\")\n",
    "print(f\"Average number of words in textual reviews of RB : {mean_words_RB}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top N most common words after preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can take 5-7 min to run on all the sentences\n",
    "N = 20\n",
    "\n",
    "# BeerAdvocate\n",
    "common_unigrams_BA = get_top_n_i_gram(ratings_BA_cleaned['cleaned_text'], 1, N)\n",
    "common_bigrams_BA = get_top_n_i_gram(ratings_BA_cleaned['cleaned_text'], 2, N)\n",
    "common_trigrams_BA = get_top_n_i_gram(ratings_BA_cleaned['cleaned_text'], 3, N)\n",
    "# Rate Beer\n",
    "common_unigrams_RB = get_top_n_i_gram(ratings_RB_cleaned['cleaned_text'], 1, N)\n",
    "common_bigrams_RB = get_top_n_i_gram(ratings_RB_cleaned['cleaned_text'], 2, N)\n",
    "common_trigrams_RB = get_top_n_i_gram(ratings_RB_cleaned['cleaned_text'], 3, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ngrams(common_unigrams, common_bigrams, common_trigrams):\n",
    "    # Creating subplots\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(17, 5))\n",
    "\n",
    "    # Subplot 1: Common Unigrams\n",
    "    df1 = pd.DataFrame(common_unigrams, columns=['Review Text', 'count'])\n",
    "    df1.groupby('Review Text').sum()['count'].sort_values(ascending=False).plot(kind='barh', y='Count', ax=axes[0])\n",
    "    axes[0].set_title(f'Top {N} words in reviews')\n",
    "\n",
    "    # Subplot 2: Common Bigrams\n",
    "    df2 = pd.DataFrame(common_bigrams, columns=['Review Text', 'count'])\n",
    "    df2.groupby('Review Text').sum()['count'].sort_values(ascending=False).plot(kind='barh', y='Count', ax=axes[1])\n",
    "    axes[1].set_title(f'Top {N} bigrams in reviews')\n",
    "\n",
    "    # Subplot 3: Common Trigrams\n",
    "    df3 = pd.DataFrame(common_trigrams, columns=['Review Text', 'count'])\n",
    "    df3.groupby('Review Text').sum()['count'].sort_values(ascending=False).plot(kind='barh', y='Count', ax=axes[2])\n",
    "    axes[2].set_title(f'Top {N} trigrams in reviews')\n",
    "\n",
    "    # Adjust layout and display\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"##### BeerAdvocate\"))\n",
    "plot_ngrams(common_unigrams_BA, common_bigrams_BA, common_trigrams_BA)\n",
    "display(Markdown(\"##### RateBeer\"))\n",
    "plot_ngrams(common_unigrams_RB, common_bigrams_RB, common_trigrams_RB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that some words are very recurring like aroma, taste, sweet both in words and expressions. This analysis can be linked to the correlation matrix where we can see that the rating is correlated to these aspects in the numerical ratings. So these are clearly most important aspects in the way to rate beers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Feasibility check of project's methods\n",
    "\n",
    "This part aims at verifying if our project plans are reasonable and sound. We will thus check that the ratings and the sentiment analysis (such as polarity and subjectivity) are not homogeneous across breweries, styles and by extension to users. It will thus support our idea to correct the ratings based on the reviews.\n",
    "\n",
    "### 1. Ratings distribution\n",
    "\n",
    "**Ratings intervals**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of beers per rating interval\n",
    "def count_beers_per_rating_interval(beers_df):\n",
    "    beers_score =[]\n",
    "    brewery_counts = []\n",
    "    for i in range(5):\n",
    "        beers_score.append(beers_df[(i < beers_df['overall']) & (beers_df['overall'] <= i+1)])\n",
    "        brewery_counts.append(beers_score[i]['brewery_name'].value_counts().sort_index())\n",
    "    return brewery_counts\n",
    "\n",
    "breweries_rating_counts_BA = count_beers_per_rating_interval(ratings_BA)\n",
    "breweries_rating_counts_RB = count_beers_per_rating_interval(ratings_RB)\n",
    "\n",
    "# Dataframe with the number of beers per rating interval matched with the brewery name\n",
    "# Create a dataframe with the different lists in breweries_rating_counts_BA as columns matching in the brewery name for the rows\n",
    "def breweries_rating_counts(beers_df):\n",
    "    breweries_rating_counts = pd.concat(count_beers_per_rating_interval(beers_df), axis=1, keys=['0-1', '1-2', '2-3', '3-4', '4-5'])\n",
    "    breweries_rating_counts.index.name = 'Brewery Name'\n",
    "    breweries_rating_counts.fillna(0, inplace=True)\n",
    "    breweries_rating_counts = breweries_rating_counts.astype(int)\n",
    "    return breweries_rating_counts\n",
    "\n",
    "df_breweries_rating_counts_BA = breweries_rating_counts(ratings_BA)\n",
    "df_breweries_rating_counts_RB = breweries_rating_counts(ratings_RB)\n",
    "\n",
    "# Create a stacked barplot for the number of beers per rating interval for BeerAdvocate\n",
    "fig, axs = plt.subplots(1,2, figsize=(15, 8))\n",
    "df_breweries_rating_counts_BA.sort_values(by='4-5', ascending=False).iloc[:10].plot.bar(stacked=True, rot=90, ax = axs[0])\n",
    "axs[0].set_title('BeerAdvocate')\n",
    "axs[0].set_xlabel('Brewery Name')\n",
    "axs[0].set_ylabel('Count')\n",
    "\n",
    "# Create a stacked barplot for the number of beers per rating interval for RateBeer\n",
    "df_breweries_rating_counts_RB.sort_values(by='4-5', ascending=False).iloc[:10].plot.bar(stacked=True, rot=90, ax = axs[1])\n",
    "axs[1].set_title('RateBeer')\n",
    "axs[1].set_xlabel('Brewery Name')\n",
    "axs[1].set_ylabel('Count')\n",
    "plt.suptitle(\"Number of beers per score interval for the best rated breweries\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This stacked barplot represents the number of beers per brewery that has the biggest number of 5 rated beers, the stacked plot is used to show the proportion of beers rated in the different intervals of score. This representation gives a more detailed representation of the distribution of scores per beers for each brewery.\n",
    "\n",
    "One can see that the ratings are not equally distributed for the same brewery, especially for the breweries from BeerAdvocate. One user very unhappy with a beer from a brewery in BeerAdvocate could thus have a big influence on the average grade of the brewery and its rating could thus be ponderated in the new ranking system we want to implement as part of our research question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ratings in function of the time**\n",
    "\n",
    "To asses whether the yearly evolution of the tastes changes, the following plot shows the evolution of the average rating per month along the years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_most_rated_beer_style_per_month(df, name):\n",
    "    \"\"\"\n",
    "    Plots the most consumed beer style per month.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        The input DataFrame to be used for plotting.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "                \n",
    "    \"\"\"\n",
    "    # group the data by month and beer style\n",
    "    df_month_style = df.groupby(['month', 'style']).size().reset_index(name='count')\n",
    "\n",
    "    # get the most consumed beer style per month\n",
    "    idx = df_month_style.groupby(['month'])['count'].transform(max) == df_month_style['count']\n",
    "    df_most_consumed = df_month_style[idx]\n",
    "\n",
    "    # plot the most consumed beer style per month\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.barplot(x=\"month\", y=\"count\", hue=\"style\", data=df_most_consumed)\n",
    "    plt.title(\"Most rated beer style per month for {}\".format(name))\n",
    "    plt.xlabel(\"Month\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_most_rated_beer_style_per_month(ratings_BA_monthly, \"BeerAdvocate\")\n",
    "plot_most_rated_beer_style_per_month(ratings_RB_monthly, \"RateBeer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to determine the evolution in time of the prefered beer style in RateBeer and the prefered beer style in function of months. This will be interesting to determine the best beer in function of the season for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSubjectivity(text):\n",
    "    return TextBlob(text).sentiment.subjectivity\n",
    "\n",
    "def getPolarity(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "def getAnalysis(score):\n",
    "    if score < 0:\n",
    "        return 'Negative'\n",
    "    elif score == 0:\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        return 'Positive'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Polarity - subjectivity per website**\n",
    "\n",
    "BeerAdvocate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can take 6-8 min to run on all the sentences\n",
    "\n",
    "# with original text\n",
    "ratings_BA_cleaned['polarity_text'] = ratings_BA_cleaned['text'].apply(lambda x: getPolarity(x))\n",
    "ratings_BA_cleaned['subjectivity_text'] = ratings_BA_cleaned['text'].apply(lambda x: getSubjectivity(x))\n",
    "ratings_BA_cleaned['polarity_Analysis'] = ratings_BA_cleaned['polarity_text'].apply(lambda x: getAnalysis(x))\n",
    "# with cleaned text\n",
    "ratings_BA_cleaned['polarity_cleaned_text'] = ratings_BA_cleaned['cleaned_text'].apply(lambda x: getPolarity(x))\n",
    "ratings_BA_cleaned['subjectivity_cleaned_text'] = ratings_BA_cleaned['cleaned_text'].apply(lambda x: getSubjectivity(x))\n",
    "ratings_BA_cleaned['cleaned_polarity_Analysis'] = ratings_BA_cleaned['polarity_text'].apply(lambda x: getAnalysis(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RateBeer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can take 8-10 min to run on all the sentences\n",
    "\n",
    "# with original text\n",
    "ratings_RB_cleaned['polarity_text'] = ratings_RB_cleaned['text'].apply(lambda x: getPolarity(x))\n",
    "ratings_RB_cleaned['subjectivity_text'] = ratings_RB_cleaned['text'].apply(lambda x: getSubjectivity(x))\n",
    "ratings_RB_cleaned['polarity_Analysis'] = ratings_RB_cleaned['polarity_text'].apply(lambda x: getAnalysis(x))\n",
    "# with cleaned text\n",
    "ratings_RB_cleaned['polarity_cleaned_text'] = ratings_RB_cleaned['cleaned_text'].apply(lambda x: getPolarity(x))\n",
    "ratings_RB_cleaned['subjectivity_cleaned_text'] = ratings_RB_cleaned['cleaned_text'].apply(lambda x: getSubjectivity(x))\n",
    "ratings_RB_cleaned['cleaned_polarity_Analysis'] = ratings_RB_cleaned['polarity_text'].apply(lambda x: getAnalysis(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ratings_BA_cleaned.head(2), ratings_RB_cleaned.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pie_chart(df, title):\n",
    "    polarity_counts = df['polarity_Analysis'].value_counts()\n",
    "\n",
    "    labels = polarity_counts.index\n",
    "    sizes = polarity_counts.values\n",
    "    myexplode=[0.05, 0.05, 0.05]\n",
    "    category_color = {'Positive': 'lightgreen', 'Neutral': 'lightblue', 'Negative': 'lightcoral'}\n",
    "    \n",
    "    colors = [category_color[label] for label in labels]\n",
    "    fig, ax = plt.subplots()\n",
    "    wedges, texts, autotexts = ax.pie(sizes, labels=labels, explode=myexplode, colors= colors, autopct='%1.1f%%', startangle=0, pctdistance=0.81, shadow=True)\n",
    "\n",
    "    fig.patch.set_facecolor('none')\n",
    "    ax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "    # Customize the appearance of labels and autopct values\n",
    "    plt.setp(texts, fontsize=12, fontweight='bold', color= 'black')\n",
    "    plt.setp(autotexts, fontsize=10, fontweight='bold')\n",
    "    plt.title(title, fontsize=14, fontweight='bold', color='black')\n",
    "    plt.show()\n",
    "\n",
    "plot_pie_chart(ratings_BA_cleaned, 'Distribution of Polarity in BeerAdvocate')\n",
    "plot_pie_chart(ratings_RB_cleaned, 'Distribution of Polarity in RateBeer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see with these plots that the distribution of opinions is unbalanced, for both websites peoples seem to mostly appreciate beers. However, it can be interested to check the distribution more precisely to verify if some people have extreme opinions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,4, figsize=(15, 5))\n",
    "sns.boxplot(data = ratings_BA_cleaned[['polarity_text', 'polarity_cleaned_text']], showmeans=True, meanprops={\"marker\":\"x\", \"markerfacecolor\":\"black\", \"markeredgecolor\":\"black\"}, ax = axs[0])\n",
    "sns.boxplot(data = ratings_RB_cleaned[['polarity_text', 'polarity_cleaned_text']], showmeans=True, meanprops={\"marker\":\"x\", \"markerfacecolor\":\"black\", \"markeredgecolor\":\"black\"}, ax = axs[1])\n",
    "\n",
    "sns.boxplot(data = ratings_BA_cleaned[['subjectivity_text', 'subjectivity_cleaned_text']], showmeans=True, meanprops={\"marker\":\"x\", \"markerfacecolor\":\"black\", \"markeredgecolor\":\"black\"}, ax = axs[2])\n",
    "sns.boxplot(data = ratings_RB_cleaned[['subjectivity_text', 'subjectivity_cleaned_text']], showmeans=True, meanprops={\"marker\":\"x\", \"markerfacecolor\":\"black\", \"markeredgecolor\":\"black\"}, ax = axs[3])\n",
    "\n",
    "for i in range(4):\n",
    "    axs[i].set_xticklabels(['Text', 'Cleaned Text'])\n",
    "\n",
    "axs[0].set_title(f\"Polarity BA\")\n",
    "axs[1].set_title(f\"Polarity RB\")\n",
    "axs[2].set_title(f\"Subjectivity BA\")\n",
    "axs[3].set_title(f\"Subjectivity RB\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These polarity’s boxplots and subjectivity’s boxplots help us to valide our idea. Indeed, we observe that our idea to create a new ranking’s system with less subjectivity, and with less weight for extreme user’s opinion which can be ponderated to limit their influence on the beer’s ranking seems to be feasible and relevant. Then, the average which is not a robust parameter would be fairer. We also see that there is not much difference between the text and cleaned text, so that we will later only use the cleaned text to perform sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Polarity - subjectivity per brewery**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_polarity_subjectivity_per_topk_brewery(website):\n",
    "    if website == 'BeerAdvocate': \n",
    "        df = ratings_BA_cleaned\n",
    "    else:\n",
    "        df = ratings_RB_cleaned\n",
    "    k_breweries = 0.9995\n",
    "    ratings_topk_breweries = filter_topk_breweries(df, k_breweries)\n",
    "\n",
    "    fig, axs = plt.subplots(1,2, figsize=(15, 6), sharey = True)\n",
    "    sns.boxplot(data = ratings_topk_breweries, x = 'polarity_text', y = 'style', showmeans=True, meanprops={\"marker\":\"x\", \"markerfacecolor\":\"black\", \"markeredgecolor\":\"black\"}, ax = axs[0])\n",
    "    sns.boxplot(data = ratings_topk_breweries, x = 'subjectivity_text', y = 'style', showmeans=True, meanprops={\"marker\":\"x\", \"markerfacecolor\":\"black\", \"markeredgecolor\":\"black\"}, ax = axs[1])\n",
    "\n",
    "    axs[0].set_title(f\"Polarity top {np.round(100*(1-k_breweries),3)} % breweries\")\n",
    "    axs[1].set_title(f\"Subjectivity top {np.round(100*(1-k_breweries),3)} % breweries\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"##### Beer Advocate\"))\n",
    "plot_polarity_subjectivity_per_topk_brewery(website = 'BeerAdvocate')\n",
    "display(Markdown(\"##### RateBeers\"))\n",
    "plot_polarity_subjectivity_per_topk_brewery(website = 'RateBeer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can note that the polarity and subjectivity of textual reviews depends on the brewery we look at. Some have more extreme outliers than others and typically for BeerAdvocate, one can note that even the mean of the polarity is different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Polarity - subjectivity per style**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_polarity_subjectivity_per_topk_style(website):\n",
    "    if website == 'BeerAdvocate': \n",
    "        df = ratings_BA_cleaned\n",
    "    else:\n",
    "        df = ratings_RB_cleaned\n",
    "    k_styles = 0.9\n",
    "    ratings_topk_styles = filter_topk_styles(df, k_styles)\n",
    "\n",
    "    fig, axs = plt.subplots(1,2, figsize=(15, 4), sharey = True)\n",
    "    sns.boxplot(data = ratings_topk_styles, x = 'polarity_text', y = 'style', showmeans=True, meanprops={\"marker\":\"x\", \"markerfacecolor\":\"black\", \"markeredgecolor\":\"black\"}, ax = axs[0])\n",
    "    sns.boxplot(data = ratings_topk_styles, x = 'subjectivity_text', y = 'style', showmeans=True, meanprops={\"marker\":\"x\", \"markerfacecolor\":\"black\", \"markeredgecolor\":\"black\"}, ax = axs[1])\n",
    "\n",
    "    axs[0].set_title(f\"Polarity top {np.round(100*(1-k_styles),0)} % styles\")\n",
    "    axs[1].set_title(f\"Subjectivity top {np.round(100*(1-k_styles),0)} % styles\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"##### BeerAdvocate\"))\n",
    "plot_polarity_subjectivity_per_topk_style(website = 'BeerAdvocate')\n",
    "display(Markdown(\"##### RateBeers\"))\n",
    "plot_polarity_subjectivity_per_topk_style(website = 'RateBeer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can note that the polarity and subjectivity of textual reviews depends also on the style of the beer we look at. Some have more extreme outliers than others eventhough one can note that the differences of polarity and subjectivity of the textual reviews across styles are less important than for breweries.\n",
    "\n",
    "It thus support the feasibility of our research project to create a weighted ranking system taking into account the discrepancies of polarity and subjectivity of the textual reviews across breweries, styles and ultimately users to have an enhanced ranking system that leverage numerical ratings and textual reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a score with polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_RB_bis= ratings_RB.copy()\n",
    "ratings_RB_bis['adapted_polarity_cleaned_text'] = (ratings_RB_cleaned['polarity_cleaned_text']+1)*5/2\n",
    "ratings_BA_bis['adapted_polarity_cleaned_text'] = (ratings_BA_cleaned['polarity_cleaned_text']+1)*5/2\n",
    "ratings_RB_bis['overall'] = ratings_RB['overall']*5/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ratings_RB_cleaned_polarity_mean = ratings_RB_cleaned['adapted_polarity_cleaned_text'].mean()\n",
    "#ratings_BA_cleaned_polarity_mean = ratings_BA_cleaned['adapted_polarity_cleaned_text'].mean()\n",
    "#ratings_BA_cleaned_mean = ratings_BA_cleaned['overall'].mean()\n",
    "#ratings_RB_cleaned_mean = ratings_RB_cleaned['overall'].mean()\n",
    "#display(ratings_RB_cleaned_polarity_mean, ratings_RB_cleaned_mean)\n",
    "#display(ratings_BA_cleaned_polarity_mean, ratings_BA_cleaned_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_ratings_BA = (ratings_BA_cleaned['overall']+ (ratings_BA_cleaned['adapted_polarity_cleaned_text']))/2\n",
    "#new_ratings_RB = (ratings_RB_cleaned_bis['overall']+ratings_RB_cleaned['adapted_polarity_cleaned_text'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(new_ratings_RB.mean(), new_ratings_BA.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_BA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_matched_test = ratings_matched.copy(deep=True)\n",
    "ratings_matched_test['beer_id.1'] = ratings_matched_test['beer_id']\n",
    "ratings_matched_test['brewery_id.1'] = ratings_matched_test['brewery_id']\n",
    "ratings_matched_test['beer_name.1'] = ratings_matched_test['beer_name']\n",
    "ratings_matched_test['brewery_name.1'] = ratings_matched_test['brewery_name']\n",
    "ratings_matched_test_1 = ratings_matched_test.iloc[:, :17]\n",
    "ratings_matched_test_1 = ratings_matched_test_1.drop(['review'], axis=1)\n",
    "ratings_matched_test_2 = ratings_matched_test.iloc[:, 17:]\n",
    "ratings_matched_test_2['overall.1'] = ratings_matched_test_2['overall.1']*5/20\n",
    "ratings_matched_test_2['aroma.1'] = ratings_matched_test_2['aroma.1']*5/10\n",
    "ratings_matched_test_2['taste.1'] = ratings_matched_test_2['taste.1']*5/10\n",
    "ratings_matched_test_2.columns = ratings_matched_test_1.columns\n",
    "ratings_matched_test = pd.concat([ratings_matched_test_1, ratings_matched_test_2], axis=0)\n",
    "ratings_matched_test.sort_values(by=['beer_id', 'user_id'], inplace=True)\n",
    "ratings_matched_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data= pd.concat([ratings_BA,ratings_RB_bis,ratings_matched_test], axis=0)\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_review = all_data.count()['overall']\n",
    "number_of_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_mean = all_data.groupby('beer_id')['overall'].agg(['count', 'mean']).dropna()\n",
    "beer_mean_TCL = beer_mean[beer_mean['count'] > 10].rename(columns={'mean': 'mean_rating'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_mean_TCL.sort_values(ascending=False, by = 'mean_rating').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_mean.sort_values(ascending=False, by = 'mean').head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = range(1, 1000)  # Adjust the range as needed\n",
    "mean_ratings = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    filtered_data = all_data.groupby('beer_id')['overall'].count() >= threshold\n",
    "    filtered_beer_ids = filtered_data[filtered_data].index\n",
    "    mean_rating = all_data[all_data['beer_id'].isin(filtered_beer_ids)]['overall'].mean()\n",
    "    mean_ratings.append(mean_rating)\n",
    "\n",
    "# Create a line plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot( thresholds,mean_ratings, color='blue')\n",
    "plt.xlabel('Review Threshold')\n",
    "plt.ylabel('Mean Rating')\n",
    "plt.title('Mean Rating in Relation to Review Threshold')\n",
    "plt.show()\n",
    "\n",
    "# peut être un effet de masse donc on va regarder si il existe un treshold relevant "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "thresholds = range(1, 1000)  # Adjust the range as needed\n",
    "mean_ratings_top_10 = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    filtered_data = all_data.groupby('beer_id')['overall'].count() >= threshold\n",
    "    filtered_beer_ids = filtered_data[filtered_data].index\n",
    "    mean_ratings = all_data[all_data['beer_id'].isin(filtered_beer_ids)].groupby('beer_id')['overall'].mean()\n",
    "    mean_ratings_top_10.append(mean_ratings.sort_values(ascending=False).head(10))\n",
    "\n",
    "# Create a line plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(thresholds, [ratings.mean() for ratings in mean_ratings_top_10], color='blue')  # Using the mean of top 10 ratings\n",
    "plt.xlabel('Review Threshold')\n",
    "plt.ylabel('Mean Rating of Top 10 Beers')\n",
    "plt.title('Mean Rating of Top 10 Beers in Relation to Review Threshold')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "thresholds = range(1, 1000)  # Adjust the range as needed\n",
    "mean_ratings_top_10_brew = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    filtered_data = all_data.groupby('brewery_id')['overall'].count() >= threshold\n",
    "    filtered_beer_ids = filtered_data[filtered_data].index\n",
    "    mean_ratings = all_data[all_data['brewery_id'].isin(filtered_beer_ids)].groupby('brewery_id')['overall'].mean()\n",
    "    mean_ratings_top_10_brew.append(mean_ratings.sort_values(ascending=False).head(10))\n",
    "\n",
    "# Create a line plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(thresholds, [ratings.mean() for ratings in mean_ratings_top_10_brew], color='blue')  # Using the mean of top 10 ratings\n",
    "plt.xlabel('Review Threshold')\n",
    "plt.ylabel('Mean Rating of Top 10 Beers')\n",
    "plt.title('Mean Rating of Top 10 Beers in Relation to Review Threshold')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donc on peut prendre un treshold de 50 reviews car il y a un plateau pour les 2 top 10 et puis -50 reviews on peut pas dire que c'est la meilleure avec si peu d'avis\n",
    "Cohérent avec un TCL en plus donc on est okay.\n",
    "Voici ici le top 10 des bières avec minimum 50 reviews: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## En fait problème très peu avec autant de reviews avec dataset total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(beer_mean_TCL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(beer_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_data['beer_id'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "new ratings= (Rnum + Rpol)(1-subj) pour chaque overall mais si pas de commentaires comment on fait?\n",
    "ensuite regrouper chaque bière de chaq\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
